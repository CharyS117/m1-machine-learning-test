{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "97beeb22",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrdbourke/m1-machine-learning-test/blob/main/00_cifar10_tinyvgg_benchmark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5TSbi6c74A6E",
      "metadata": {
        "id": "5TSbi6c74A6E"
      },
      "source": [
        "# CIFAR10 TinyVGG Benchmark\n",
        "\n",
        "The following notebook tests the speed at which a given device can perform training iterations on the [CIFAR10 dataset](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/cifar10/load_data) (10 classes, 50,000 training images, 10,000 testing images) training the TinyVGG architecture as a base.\n",
        "\n",
        "It's designed to be a simple test to compare Apple's M1 (normal, Pro, Max) to each other and other sources of compute.\n",
        "\n",
        "| Model | Dataset | Train Size | Test Size |\n",
        "| ----- | ----- | ----- | ----- |\n",
        "| [TinyVGG](https://poloclub.github.io/cnn-explainer/) (trained from scratch) | CIFAR10 (from TensorFlow Datasets) | ~50,000 (32x32x3) images | ~10,000 (32x32x3) images|\n",
        "\n",
        "## Resources\n",
        "* Code on GitHub: https://github.com/mrdbourke/m1-machine-learning-test\n",
        "* Code in this notebook adapted from: https://dev.mrdbourke.com/tensorflow-deep-learning/03_convolutional_neural_networks_in_tensorflow/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06JiS98-5DvF",
      "metadata": {
        "id": "06JiS98-5DvF"
      },
      "source": [
        "## Check for GPU\n",
        "\n",
        "If you're using Google Colab, you'll need to activate a GPU:\n",
        "1. Go to \"Runtime\"\n",
        "2. Go to \"Change Runtime Type\"\n",
        "3. Select \"GPU\"\n",
        "4. Click \"Save\" (this will restart the runtime)\n",
        "\n",
        "If you're using a Mac with an M1 chip, the GPU should already be selected if you've installed TensorFlow correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LbLhLej4JbQE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbLhLej4JbQE",
        "outputId": "96c253b3-fb77-4abe-c06d-a616aef387f5"
      },
      "outputs": [],
      "source": [
        "# This will error if not using a Nvidia GPU (only works on Colab)\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bHGp6bH5OCm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bHGp6bH5OCm",
        "outputId": "71c42d9d-86f1-4748-fd23-71291ac55259"
      },
      "outputs": [],
      "source": [
        "# Check for GPU using TensorFlow\n",
        "import tensorflow as tf\n",
        "tf.config.list_physical_devices()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cQ4yT7yE6heC",
      "metadata": {
        "id": "cQ4yT7yE6heC"
      },
      "source": [
        "## Setup hyperparameters\n",
        "\n",
        "Change these to suit your needs.\n",
        "\n",
        "The main one will be the device you're running code on.\n",
        "\n",
        "E.g. `DEVICE = \"Google Colab (K80 GPU)\"` if using Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "L8nDFuw_6tCE",
      "metadata": {
        "id": "L8nDFuw_6tCE"
      },
      "outputs": [],
      "source": [
        "# Setup hyperparameters\n",
        "BATCH_SIZE = 32 # good for your health: https://twitter.com/ylecun/status/989610208497360896\n",
        "EPOCHS = 10 # only run for a short period of time... we don't have all day\n",
        "DATASET_NAME = \"cifar10\" # change this to try other image datasets from TensorFlow Datasets\n",
        "DEVICE = \"Google Colab (K80 GPU)\" # change this depending on where you're runing the code"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc0MfFZU5HhS",
      "metadata": {
        "id": "fc0MfFZU5HhS"
      },
      "source": [
        "## Get helper functions and import dependencies\n",
        "\n",
        "The function below downloads the helper functions if necessary (if running this notebook in Google Colab, it's easier to download a single file than clone the whole repo)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UBY_EONu5HQk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBY_EONu5HQk",
        "outputId": "cf5504aa-2afc-497a-af66-a9e88d98f747"
      },
      "outputs": [],
      "source": [
        "# Get helper functions\n",
        "import os\n",
        "import requests\n",
        "\n",
        "if not os.path.exists(\"helper_functions.py\"):\n",
        "  print(\"Downloading helper functions...\")\n",
        "  r = requests.get(\"https://raw.githubusercontent.com/mrdbourke/m1-machine-learning-test/main/helper_functions.py\")\n",
        "  print(\"Writing helper functions to file...\")\n",
        "  open(\"helper_functions.py\", \"wb\").write(r.content)\n",
        "else:\n",
        "  print(\"Helper functions already downloaded, skipping redownload.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8f23a80",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8f23a80",
        "outputId": "68ecf66a-e18f-475b-b389-4283bd45b861"
      },
      "outputs": [],
      "source": [
        "# Check TensorFlow version\n",
        "import tensorflow as tf\n",
        "print(tf.__version__) # should be 2.5.0+\n",
        "\n",
        "# Get TensorFlow Datasets\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Get data science libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from timeit import default_timer as timer \n",
        "from helper_functions import print_train_time"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2425d422",
      "metadata": {
        "id": "2425d422"
      },
      "source": [
        "## Get data from TensorFlow Keras Datasets\n",
        "\n",
        "Let's download the data and inspect it. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1dcec42",
      "metadata": {
        "id": "d1dcec42"
      },
      "outputs": [],
      "source": [
        "# Get data from tf.keras.datasets\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea3b59dd",
      "metadata": {
        "id": "ea3b59dd"
      },
      "outputs": [],
      "source": [
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db015720",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "db015720",
        "outputId": "d4e8157f-0f92-434e-d379-94150bf12585"
      },
      "outputs": [],
      "source": [
        "# Inspect image\n",
        "image = train_images[0]\n",
        "label = int(train_labels[0])\n",
        "\n",
        "print(f\"\"\"\n",
        "  Image shape: {image.shape}\n",
        "  Image dtype: {image.dtype}\n",
        "  Target class from Food101: {label}\n",
        "  Class name (str form): {class_names[label]}\n",
        "        \"\"\")\n",
        "plt.imshow(image)\n",
        "plt.title(class_names[label])\n",
        "plt.axis(False);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uif5hgCa5tpp",
      "metadata": {
        "id": "uif5hgCa5tpp"
      },
      "source": [
        "## Prepare data\n",
        "\n",
        "The data looks good. But before we model it, we're going to prepare it to run as fast as possible using [TensorFlow data loading best practices](https://www.tensorflow.org/guide/data_performance)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c862c1e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c862c1e",
        "outputId": "2ad14326-e58d-4fea-9e37-04a8c3761495"
      },
      "outputs": [],
      "source": [
        "# Create datasets \n",
        "train_data = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "test_data = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "\n",
        "# Make datasets faster\n",
        "train_data = train_data.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_data = test_data.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_data, test_data, len(train_data), len(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25d58b30",
      "metadata": {
        "id": "25d58b30"
      },
      "source": [
        "## Setup and fit model\n",
        "\n",
        "To keep things simple, we're going to use the TinyVGG architecture from the [CNN explainer website](https://poloclub.github.io/cnn-explainer/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7938027f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7938027f",
        "outputId": "87e95c58-acb6-46ad-a2c7-e373daf25add"
      },
      "outputs": [],
      "source": [
        "def model_fit():\n",
        "  # Setup hyperparameters\n",
        "  BATCH_SIZE = 32 # good for your health: https://twitter.com/ylecun/status/989610208497360896\n",
        "  EPOCHS = 10 # only run for a short period of time... we don't have all day\n",
        "  DATASET_NAME = \"cifar10\" # change this to try other image datasets from TensorFlow Datasets\n",
        "  DEVICE = \"Google Colab (K80 GPU)\" # change this depending on where you're runing the code\n",
        "  EPOCHS = 10\n",
        "  # Get data from tf.keras.datasets\n",
        "  (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "  # Normalize pixel values to be between 0 and 1\n",
        "  train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "  class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "  # Create datasets \n",
        "  train_data = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "  test_data = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "\n",
        "  # Make datasets faster\n",
        "  train_data = train_data.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "  test_data = test_data.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "  train_data, test_data, len(train_data), len(test_data)\n",
        "  # Set random seed\n",
        "  tf.random.set_seed(42)\n",
        "\n",
        "  # Start time\n",
        "  start_time = timer()\n",
        "\n",
        "  # Create a CNN model (same as Tiny VGG - https://poloclub.github.io/cnn-explainer/)\n",
        "  model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters=10, \n",
        "                          kernel_size=3, # can also be (3, 3)\n",
        "                          activation=\"relu\", \n",
        "                          input_shape=(32, 32, 3)), # first layer specifies input shape (height, width, colour channels)\n",
        "    tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=2, # pool_size can also be (2, 2)\n",
        "                              padding=\"valid\"), # padding can also be 'same'\n",
        "    tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n",
        "    tf.keras.layers.Conv2D(10, 3, activation=\"relu\"), # activation='relu' == tf.keras.layers.Activations(tf.nn.relu)\n",
        "    tf.keras.layers.MaxPool2D(2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\") # multi-class activation output\n",
        "  ], name=\"TinyVGG\")\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(loss=\"sparse_categorical_crossentropy\", # since labels aren't one-hot, use sparse_categorical_crossentropy\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "  # Fit model \n",
        "  history = model.fit(train_data,epochs=EPOCHS,steps_per_epoch=len(train_data),validation_data=test_data,validation_steps=len(test_data))\n",
        "  end_time = timer()\n",
        "  train_time = print_train_time(start_time, \n",
        "                              end_time, \n",
        "                              device=DEVICE)\n",
        "\n",
        "import multiprocessing\n",
        "\n",
        "process_eval = multiprocessing.Process(target=model_fit)\n",
        "process_eval.start()\n",
        "process_eval.join()\n",
        "# Track time "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qymGk8mw6VaD",
      "metadata": {
        "id": "qymGk8mw6VaD"
      },
      "source": [
        "## Track results and save to file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cferSb088tne",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "cferSb088tne",
        "outputId": "d88d79a3-6079-485f-ad98-bca241cf5359"
      },
      "outputs": [],
      "source": [
        "results = {\n",
        "    \"device\": DEVICE,\n",
        "    \"dataset_name\": DATASET_NAME,\n",
        "    \"epochs\": EPOCHS,\n",
        "    \"batch_size\": BATCH_SIZE,\n",
        "    \"num_train_samples\": len(train_data)*BATCH_SIZE,\n",
        "    \"num_test_samples\": len(test_data)*BATCH_SIZE,\n",
        "    \"total_train_time\": round(train_time, 3),\n",
        "    \"time_per_epoch\": round(train_time/EPOCHS, 3),\n",
        "    \"model\": model.name\n",
        "    }\n",
        "results_df = pd.DataFrame(results, index=[0])\n",
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9Z4oPZYi8y1Y",
      "metadata": {
        "id": "9Z4oPZYi8y1Y"
      },
      "outputs": [],
      "source": [
        "# Write CSV to file\n",
        "if not os.path.exists(\"results/\"):\n",
        "  os.makedirs(\"results/\")\n",
        "\n",
        "results_df.to_csv(f\"results/{DEVICE}_{DATASET_NAME}.csv\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "00_cifar10_tinyvgg_benchmark.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
